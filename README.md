# Real-Time ETL Streaming Pipeline Using Apache Beam and Google Dataflow

## Overview
This project demonstrates how to build an end-to-end real-time data analytics pipeline using Google Cloud Platform (GCP) services. The pipeline ingests streaming data, processes it in real-time, and stores the results for analytics and visualization. It leverages several GCP components such as Pub/Sub, Dataflow, BigQuery, and Looker Studio.

## Architecture
The pipeline consists of the following components:
- **Data Ingestion (Pub/Sub)**: Captures real-time data streams.
- **Stream Processing (Dataflow)**: Applies real-time transformations and aggregations to the data.
- **Data Storage (BigQuery)**: Stores processed data for long-term analysis.
- **Visualization (Tableau)**: Provides dashboards and real-time data insights.

## Key Features
- **Scalable and Reliable**: The pipeline is designed to handle large-scale, continuous data streams efficiently.
- **Real-Time Processing**: Data is processed and analyzed as it is ingested, providing near real-time insights.
- **Serverless Architecture**: Most components, such as Pub/Sub and Dataflow, are managed services, reducing operational overhead.
  
## Technologies Used
- **Google Pub/Sub**: Message ingestion and delivery service for real-time data.
- **Google Dataflow**: Managed stream processing with Apache Beam.
- **BigQuery**: Serverless, highly scalable data warehouse for analytics.
- **Tableau**: Visualization tool for creating interactive dashboards.
- **Python**: Used for pipeline orchestration and Dataflow jobs.




## Reference

https://randomuser.me/ \
https://beam.apache.org/documentation/ \
https://chatgpt.com/ \
https://cloud.google.com/docs \
https://www.cloudskillsboost.google/paths/16 \
https://github.com/GoogleCloudPlatform/training-data-analyst/ \
https://github.com/GoogleCloudPlatform/training-data-analyst/ \
https://www.youtube.com/watch?v=IbZHLDKNwRE&list=PLGZpjgRdXegmkexUk_PN8g_V9FRywAad-

